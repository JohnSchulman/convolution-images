# -*- coding: utf-8 -*-
"""TP3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TblZoX1zUPS2qmWzTlYKv3nQhy-cR9DQ
"""

# import des packages
# d'autres packages sont ajouté au fur et à mesure
from contextlib import contextmanager
import os
import sys
import pandas as pd
@contextmanager
def suppress_stdout():
  with open(os.devnull, "w") as devnull:
    old_stdout = sys.stdout
    sys.stdout = devnull
    try:
        yield
    finally:
      sys.stdout = old_stdout

# permet d'importer facilement le fichier Json

file = open('/content/kaggle.json', 'w')
file.write('{"username":"mariejeanneschulman","key":"dcb8389023a7d3b8c706f767db7aa0e3"}')
file.close()

!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!ls ~/.kaggle

!chmod 600 /root/.kaggle/kaggle.json
# ici le chemin sur kaggle du dataset
!kaggle datasets download -d playlist/men-women-classification

print("unzipping files...")
with suppress_stdout():
  !unzip men-women-classification.zip
print("files unzipped...")

import pandas as pd
# Phase de preprocessing 
# Préparation des données d'entrainement et de tests

mens = os.listdir("data/men")
print(mens)
womens = os.listdir("data/women")
print(womens)
categories = []
filenames = []

# Je boucle sur mes deux tableaux et j'attrbut une label "men", "woman"
# ainsi qu'une categories : 1 ou 0
for men in mens:
    filenames.append("men/" + men)
    categories.append(1)

for women in womens:   
        filenames.append("women/" + women)    
        categories.append(0)

# pour que toutes notre dossier soit dans une seul tableau
# je combine mes labels et catégories dans un seul dataframe
df = pd.DataFrame({
    'filename': filenames,
    'category': categories
})

# affiche les 5 premiers elements pour tester
df.head(5)

# affiche les 5 derniers
df.tail()

import random
import matplotlib.pyplot as plt
from keras.preprocessing.image import ImageDataGenerator, load_img

# Je choisi une image aléatoire et je l'affiche
sample = random.choice(mens)
menImage = load_img("data/men/"+ sample)
plt.imshow(menImage)

#sample2 = random.choice(womens)
#womenImage = load_img("data/women/"+sample2)
#plt.imshow(womenImage)

# Mes Constants utilisé dans mon modèle
FAST_RUN = False
IMAGE_WIDTH=128
IMAGE_HEIGHT=128
IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)
IMAGE_CHANNELS=3

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization


# Mon modèle
# Comme je traite des images je vais m'en servir de convolutions qui permet de concentrer sur des traits distinctives selon des matrices
# On peux parler de features map car on traite des images qui gère la profondeur d'une image.
# Pour y arriver on fait appel à des outils comme
# MaxPooling : prends que les pixels essentiels. Elimine ceux qui ne sont pas pertinants
# Relu :(nombre positives) Une sort de tuyau pour inclure que les valeurs positives. Les zero sont mis à null pour dire ca je ne veux pas
# Softmax :(nombre entre 0 et 1) Concerne la dernière couche
#          Ramène les valeurs entre 0 et 1 pour pouvoir creer un ecart et recuperer la plus forte des neurones de sorties
# Dropout :Traites les images avec un peu d'aléatoire/flou pour ne pas surapprendre 
model = Sequential()

model.add(Conv2D(256, (5, 5), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))
model.add(Conv2D(256, (7, 7), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(128, (7, 7), activation='relu'))
model.add(Conv2D(128, (7, 7), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))   

model.add(Conv2D(64, (7, 7), activation='relu'))
model.add(Conv2D(64, (7, 7), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))

model.add(Conv2D(32, (7, 7), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax')) # 2  car on deux classes

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.summary()

# on remplace 0 par men et 1 par women
df["category"] = df["category"].replace({0: 'men', 1: 'women'})

from sklearn.model_selection import train_test_split

# on divise notre dataframe en données d'entrainement (80%)
# et données de tests (20%) 
# On profite aussi pour l'enlever l'index des deux parties
train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)
train_df = train_df.reset_index(drop=True)
validate_df = validate_df.reset_index(drop=True)

# J'affiche une graphique quantitive des nombres de données grâce à matplotlib des données d'entrainement
train_df['category'].value_counts().plot.bar()

# Même chose mais pour les données de tests
validate_df['category'].value_counts().plot.bar()

# les spécificités de l'entrainement et de tests
# on cherche just maintenant juste à récupérer le label ou filename
# shape renvoit les dimensions/colonnes de la dataframe
#Shape[0] c'est le filename et shape[1] c'est le categories
total_train = train_df.shape[0]
total_validate = validate_df.shape[0]
batch_size=2

from keras.preprocessing.image import ImageDataGenerator, load_img

# permet des transformations aléatoires pour mieux generaliser en evitant le surapprentissage 
# cette processus s'appelle "augementer" l'image
train_datagen = ImageDataGenerator(
    rotation_range=15,
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1
)

# permet d'instancier des générateurs de batchs d'images augmentées
train_generator = train_datagen.flow_from_dataframe(
    train_df, 
    "/content/", 
    x_col='filename',
    y_col='category',
    target_size=IMAGE_SIZE,
    class_mode='categorical',
    batch_size=batch_size
)

# même chose mais pour des données de tests
validation_datagen = ImageDataGenerator(rescale=1./255)
validation_generator = validation_datagen.flow_from_dataframe(
    validate_df, 
    "/content/", 
    x_col='filename',
    y_col='category',
    target_size=IMAGE_SIZE,
    class_mode='categorical',
    batch_size=batch_size
)

import matplotlib.pyplot as plt

# permet de générer à partir d'une seul image, plusieurs images visualisé sur plusieurs angles 
plt.figure(figsize=(12, 12))
for i in range(0, 15):
    plt.subplot(5, 3, i+1)
    for X_batch, Y_batch in validation_generator:
        image = X_batch[0]
        plt.imshow(image)
        break
plt.tight_layout()
plt.show()

# Callabcks

# Trop peu d'entrainement résultera à un sous-apprentissage des données d'entrainements et de tests
# L'inverse c'est-à-dire un surapprenstissage résulte à un mauvaise performance également
# Pour trouver le juste milieu il vaut faire un compromis lorsque l'apprenttisage commence à se lasser 
# Pour y arriver on utilise des callback évoquer en bas

# Pour empêcher du overfitting c'est-à-dire du surapprentissage 
earlystop = EarlyStopping(patience=10)

# Cela empêche une surapprentissage aussi qui nuira à une descente ou hausse brutale de la courbe graphique
learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', 
                                            patience=2, 
                                            verbose=1, 
                                            factor=0.5, 
                                            min_lr=0.00001)

CALLBACKS = [earlystop, learning_rate_reduction]

epochs=3 #if FAST_RUN else 50
history = model.fit_generator(
    train_generator, 
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=total_validate//batch_size,
    steps_per_epoch=total_train//batch_size,
    shuffle=True,
    callbacks = CALLBACKS
)

model.save_weights("model.h5")

import numpy as np

#-----------------------------------------------------------
# Obtient une liste de liste de résultats sur les données 
# d'entrainement et de tests par époches
#-----------------------------------------------------------
acc = history.history['accuracy']
val_acc = history.history[ 'val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs   = range(len(acc)) # Get number of epochs

#------------------------------------------------
# Entrainement de précision de validation par époches
#------------------------------------------------
plt.plot(epochs, acc)
plt.plot(epochs, val_acc)
plt.title('Training and validation accuracy')
plt.figure()

#------------------------------------------------
# Entrainement de perte de validation par époches
#------------------------------------------------
plt.plot(epochs, loss)
plt.plot(epochs, val_loss)
plt.title('Training and validation loss')

# preparation des données de testes
test_filenames = os.listdir("/content/")
test_df = pd.DataFrame({
    'filename': filenames
})
nb_samples = test_df.shape[0]
#print(nb_samples)

# transformation aleatoire pour mieux généralisé 
test_gen = ImageDataGenerator(
    rotation_range=15,
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1)

# instancie des generateurs d'images augmenté
test_generator = test_gen.flow_from_dataframe(
    test_df, 
    "/content/", 
    x_col='filename',
    y_col=None,
    class_mode=None,
    target_size=IMAGE_SIZE,
    batch_size=batch_size,
    shuffle=False
)

# le predict_generator permet de générer une prédiction de catégories en fonction du test_generator qui lui contient que les labels.
# l'arrêt de cette prédiction c'est en fonction du steps qui lui contient nb_samples qui renvoit à la première colonnes CAD les labels (test_df.shape[0])
# nb_samples est divisé par batch_size qui concerne ne nombre d'example à traiter complètement avant la fin du boucle  
predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))

print(predict)

# Affichage en mode graphique d'une photo avec en bas une prédiction homme ou femme

for i in range(20):
  # pourcentage maximal d'un prediction
  pred_category = predict[i].argmax()
  # En fonction de ma prédiction j'attribut mes labels
  if pred_category == 0:
    label = 'woman'
  else:
    label = 'man'
# J'affiche une image à partir de mon test_generator(qui génère une image augmenté)
for X_batch in test_generator:
  image = X_batch[0]
  plt.imshow(image)
  break
# J'affiche en bas de l'image un label
plt.xlabel('prediction is :  ' + label)
plt.show()